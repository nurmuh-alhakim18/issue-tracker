# ğŸ› ï¸ Real-Time Issue Tracker

> ğŸ§ª This project is my attempt to learn Java by building a backend system using Spring Boot and related technologies.

A backend project built with **Spring Boot**, using a layered architecture (`controller`, `service`, `repository`) and integrating **Kafka**, **Redis**, **Elasticsearch**, and **JWT authentication** for a modern, scalable system.

---

## ğŸ“¦ Features

- âœ… JWT-based user registration & login
- ğŸ› Create, update, and comment on issues
- âš¡ Redis for caching data
- ğŸ” Full-text search with Elasticsearch
- ğŸ” Asynchronous processing with Kafka (Producer/Consumer)
- ğŸ§± Clean layered architecture (Controller â†’ Service â†’ Repository)

---

## ğŸ§° Tech Stack

- **Java 21**
- **Spring Boot 3.x**
- **Kafka** â€“ event streaming
- **Redis** â€“ caching
- **Elasticsearch** â€“ search indexing
- **PostgreSQL** â€“ main DB
- **Docker & Docker Compose** â€“ for setup
- **JWT** â€“ authentication

---

## ğŸš€ Getting Started

### ğŸ”§ Prerequisites

- Java 21+
- Maven
- Docker & Docker Compose

### ğŸ§± Clone and Start

```bash
git clone https://github.com/nurmuh-alhakim18/issue-tracker.git
cd issue-tracker
docker-compose up -d
```

---

## ğŸ—ƒï¸ Project Structure

```
src/main/java/com/alhakim/issuetracker
â”œâ”€â”€ config         # Security, Kafka, Redis configurations
â”œâ”€â”€ controller     # REST APIs
â”œâ”€â”€ dto            # Request/response DTOs
â”œâ”€â”€ entity         # JPA entities
â”œâ”€â”€ exception      # Custom exceptions and handlers
â”œâ”€â”€ middleware     # Filters and interceptors (e.g., JWT)
â”œâ”€â”€ repository     # JPA repositories
â”œâ”€â”€ service        # Business logic
â””â”€â”€ IssuetrackerApplication.java
```

---

## ğŸ” Authentication

All protected routes require:

```
Authorization: Bearer <JWT_TOKEN>
```

### Auth Endpoints

| Method | Endpoint              | Description         |
|--------|-----------------------|---------------------|
| POST   | /api/v1/auth/register | Register new user   |
| POST   | /api/v1/auth/login    | Login and get token |

---

## ğŸ”„ Kafka Integration

- ğŸ”¸ **Producer:** Emits plain string messages (e.g., "INDEX,1")
- ğŸ”¹ **Consumer:** Listens `issue-index` to index issue into Elasticsearch

---

## âš¡ Redis Usage

- Caches frequent data like issue detail
- TTL configured in `CacheConfig.java`

---

## ğŸ” Elasticsearch Usage

Supports full-text and filtered search over issues using Elasticsearch.

### ğŸ” Search Endpoint

**POST** `/api/issues/search`

**Example Request Body**:

```json
{
  "query": "login bug",
  "status": "OPEN",
  "priority": "MEDIUM",
  "tags": ["bug"],
  "orderBy": "createdAt",
  "direction": "desc",
  "page": 1,
  "size": 10
}
```

**Description**:
- `query`: Full-text search on issue titles/descriptions.
- `status`: Filter by status (e.g., `OPEN`, `CLOSED`).
- `priority`: Issue priority (`LOW`, `MEDIUM`, `HIGH`).
- `tags`: Filter by tags (e.g., `Bug`).
- `orderBy`: Field to sort by (e.g., `createdAt`, `updatedAt`).
- `direction`: Sorting direction (`asc`, `desc`).
- `page` and `size`: Pagination controls.

---

## ğŸ§ª API Endpoints

### ğŸ”¸ Admin

| Method | Endpoint                   | Description                         |
|--------|----------------------------|-------------------------------------|
| POST   | /api/v1/admin/index/issues | Bulk index issue into Elasticsearch |

### ğŸ”¸ Issues

| Method | Endpoint              | Description        |
|--------|-----------------------|--------------------|
| GET    | /api/v1/issues        | List all issues    |
| POST   | /api/v1/issues/search | Search issue       |
| POST   | /api/v1/issues        | Create a new issue |
| GET    | /api/v1/issues/{id}   | Get issue by ID    |
| PUT    | /api/v1/issues/{id}   | Update issue       |
| DELETE | /api/v1/issues/{id}   | Delete issue       |

### ğŸ”¸ Comments

| Method | Endpoint                     | Description        |
|--------|------------------------------|--------------------|
| POST   | /api/v1/issues/{id}/comments | Add comment        |
| GET    | /api/v1/issues/{id}/comments | Get all comments   |

---

## ğŸ³ Docker Compose Setup

```yaml
services:
  app:
    build: .
    ports:
      - "8000:8000"
    depends_on:
      - db
      - redis
  db:
    image: postgres:13
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=issue_tracker
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=rahasiapol
    volumes:
      - postgres_data:/var/lib/postgresql/data
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.28
    ports:
      - "9200:9200"
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    volumes:
      - elastic_data:/usr/share/elasticsearch/data
    ulimits:
      memlock:
        soft: -1
        hard: -1
  kafka:
    image: apache/kafka-native
    ports:
      - "9092:9092"
    environment:
      # Configure listeners for both docker and host communication
      KAFKA_LISTENERS: CONTROLLER://localhost:9091,HOST://0.0.0.0:9092,DOCKER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: HOST://localhost:9092,DOCKER://kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,DOCKER:PLAINTEXT,HOST:PLAINTEXT

      # Settings required for KRaft mode
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9091

      # Listener to use for broker-to-broker communication
      KAFKA_INTER_BROKER_LISTENER_NAME: DOCKER

      # Required for a single node cluster
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  kafka-ui:
    image: kafbat/kafka-ui:main
    ports:
      - 8080:8080
    environment:
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9093
    depends_on:
      - kafka

volumes:
  postgres_data:
  redis_data:
  elastic_data:
```

---

## ğŸ“œ API Documentation (Swagger)

This project uses **SpringDoc OpenAPI** for automatic Swagger UI generation.

### ğŸ”— Access

Once the app is running, access the Swagger UI at:

```
http://localhost:8000/api/v1/swagger-ui/index.html
```

You can explore all endpoints, test them interactively, and view their schema.

---

## ğŸ“Œ Future Enhancements

- WebSocket notifications
- CI/CD integration with GitHub Actions